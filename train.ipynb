{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-27T19:38:48.002387Z",
     "start_time": "2024-06-27T19:38:45.738451Z"
    }
   },
   "source": [
    "from face2embeddings.data.dataset import Arc2FaceDataset\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm \n",
    "import torch\n",
    "import os\n",
    "import time\n",
    "from torchvision.models import Swin_V2_S_Weights, swin_v2_s\n",
    "from torchinfo import summary\n",
    "from face2embeddings.model import FaceSwin"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:16:22.110527Z",
     "start_time": "2024-06-27T15:12:19.507280Z"
    }
   },
   "cell_type": "code",
   "source": "dataset = Arc2FaceDataset(path_to_dataset=Path(r\"C:\\Users\\emely\\OneDrive\\Desktop\\face-auth-dataset\\train\"))",
   "id": "daafaeb889ff1b31",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T15:16:33.343670Z",
     "start_time": "2024-06-27T15:16:33.341153Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataloader = DataLoader(\n",
    "      dataset,\n",
    "      batch_size=3,\n",
    "      shuffle=True,\n",
    "      num_workers=os.cpu_count(),\n",
    "      pin_memory=True,\n",
    "  )"
   ],
   "id": "cd3dc3f0e0f237f7",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:21:13.669893Z",
     "start_time": "2024-06-27T19:21:12.770937Z"
    }
   },
   "cell_type": "code",
   "source": "model = swin_v2_s(weights=Swin_V2_S_Weights.DEFAULT)",
   "id": "f7bbe8e634fd5be2",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:30:26.137377Z",
     "start_time": "2024-06-27T19:30:26.117150Z"
    }
   },
   "cell_type": "code",
   "source": [
    "named_layers = dict(model.named_modules())\n",
    "named_layers"
   ],
   "id": "baa32c15137f9553",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'': SwinTransformer(\n",
       "   (features): Sequential(\n",
       "     (0): Sequential(\n",
       "       (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "       (1): Permute()\n",
       "       (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (1): Sequential(\n",
       "       (0): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "           (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "         (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (1): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "           (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.013043478260869565, mode=row)\n",
       "         (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): PatchMergingV2(\n",
       "       (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "       (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (3): Sequential(\n",
       "       (0): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "           (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.02608695652173913, mode=row)\n",
       "         (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (1): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "           (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.03913043478260869, mode=row)\n",
       "         (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (4): PatchMergingV2(\n",
       "       (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "       (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (5): Sequential(\n",
       "       (0): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.05217391304347826, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (1): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (2): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.07826086956521738, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (3): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.09130434782608696, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (4): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.10434782608695652, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (5): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.11739130434782608, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (6): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (7): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.14347826086956522, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (8): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.15652173913043477, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (9): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.16956521739130434, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (10): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (11): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (12): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.20869565217391303, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (13): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.2217391304347826, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (14): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.23478260869565215, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (15): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.24782608695652175, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (16): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (17): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "           (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.27391304347826084, mode=row)\n",
       "         (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (6): PatchMergingV2(\n",
       "       (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "       (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     )\n",
       "     (7): Sequential(\n",
       "       (0): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "           (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.28695652173913044, mode=row)\n",
       "         (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "       (1): SwinTransformerBlockV2(\n",
       "         (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         (attn): ShiftedWindowAttentionV2(\n",
       "           (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "           (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "           (cpb_mlp): Sequential(\n",
       "             (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "             (1): ReLU(inplace=True)\n",
       "             (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "           )\n",
       "         )\n",
       "         (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "         (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "         (mlp): MLP(\n",
       "           (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "           (1): GELU(approximate='none')\n",
       "           (2): Dropout(p=0.0, inplace=False)\n",
       "           (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "           (4): Dropout(p=0.0, inplace=False)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (permute): Permute()\n",
       "   (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "   (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "   (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       " ),\n",
       " 'features': Sequential(\n",
       "   (0): Sequential(\n",
       "     (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "     (1): Permute()\n",
       "     (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       "   (1): Sequential(\n",
       "     (0): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "         (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "       (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (1): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "         (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.013043478260869565, mode=row)\n",
       "       (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (2): PatchMergingV2(\n",
       "     (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "     (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       "   (3): Sequential(\n",
       "     (0): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "         (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.02608695652173913, mode=row)\n",
       "       (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (1): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "         (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.03913043478260869, mode=row)\n",
       "       (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (4): PatchMergingV2(\n",
       "     (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "     (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       "   (5): Sequential(\n",
       "     (0): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.05217391304347826, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (1): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (2): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.07826086956521738, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (3): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.09130434782608696, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (4): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.10434782608695652, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (5): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.11739130434782608, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (6): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (7): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.14347826086956522, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (8): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.15652173913043477, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (9): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.16956521739130434, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (10): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (11): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (12): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.20869565217391303, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (13): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.2217391304347826, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (14): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.23478260869565215, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (15): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.24782608695652175, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (16): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (17): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "         (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.27391304347826084, mode=row)\n",
       "       (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (6): PatchMergingV2(\n",
       "     (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "     (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   )\n",
       "   (7): Sequential(\n",
       "     (0): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "         (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.28695652173913044, mode=row)\n",
       "       (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "     (1): SwinTransformerBlockV2(\n",
       "       (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "       (attn): ShiftedWindowAttentionV2(\n",
       "         (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "         (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "         (cpb_mlp): Sequential(\n",
       "           (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "           (1): ReLU(inplace=True)\n",
       "           (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "         )\n",
       "       )\n",
       "       (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "       (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): MLP(\n",
       "         (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'features.0': Sequential(\n",
       "   (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "   (1): Permute()\n",
       "   (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " 'features.0.0': Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4)),\n",
       " 'features.0.1': Permute(),\n",
       " 'features.0.2': LayerNorm((96,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.1': Sequential(\n",
       "   (0): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "       (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "     (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (1): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "       (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.013043478260869565, mode=row)\n",
       "     (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'features.1.0': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "     (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "   (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.1.0.norm1': LayerNorm((96,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.1.0.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "   (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.1.0.attn.qkv': Linear(in_features=96, out_features=288, bias=True),\n",
       " 'features.1.0.attn.proj': Linear(in_features=96, out_features=96, bias=True),\n",
       " 'features.1.0.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=3, bias=False)\n",
       " ),\n",
       " 'features.1.0.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.1.0.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.1.0.attn.cpb_mlp.2': Linear(in_features=512, out_features=3, bias=False),\n",
       " 'features.1.0.stochastic_depth': StochasticDepth(p=0.0, mode=row),\n",
       " 'features.1.0.norm2': LayerNorm((96,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.1.0.mlp': MLP(\n",
       "   (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.1.0.mlp.0': Linear(in_features=96, out_features=384, bias=True),\n",
       " 'features.1.0.mlp.1': GELU(approximate='none'),\n",
       " 'features.1.0.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.1.0.mlp.3': Linear(in_features=384, out_features=96, bias=True),\n",
       " 'features.1.0.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.1.1': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "     (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.013043478260869565, mode=row)\n",
       "   (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.1.1.norm1': LayerNorm((96,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.1.1.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "   (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.1.1.attn.qkv': Linear(in_features=96, out_features=288, bias=True),\n",
       " 'features.1.1.attn.proj': Linear(in_features=96, out_features=96, bias=True),\n",
       " 'features.1.1.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=3, bias=False)\n",
       " ),\n",
       " 'features.1.1.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.1.1.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.1.1.attn.cpb_mlp.2': Linear(in_features=512, out_features=3, bias=False),\n",
       " 'features.1.1.stochastic_depth': StochasticDepth(p=0.013043478260869565, mode=row),\n",
       " 'features.1.1.norm2': LayerNorm((96,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.1.1.mlp': MLP(\n",
       "   (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.1.1.mlp.0': Linear(in_features=96, out_features=384, bias=True),\n",
       " 'features.1.1.mlp.1': GELU(approximate='none'),\n",
       " 'features.1.1.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.1.1.mlp.3': Linear(in_features=384, out_features=96, bias=True),\n",
       " 'features.1.1.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.2': PatchMergingV2(\n",
       "   (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "   (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " 'features.2.reduction': Linear(in_features=384, out_features=192, bias=False),\n",
       " 'features.2.norm': LayerNorm((192,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.3': Sequential(\n",
       "   (0): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "       (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.02608695652173913, mode=row)\n",
       "     (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (1): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "       (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.03913043478260869, mode=row)\n",
       "     (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'features.3.0': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "     (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.02608695652173913, mode=row)\n",
       "   (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.3.0.norm1': LayerNorm((192,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.3.0.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "   (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.3.0.attn.qkv': Linear(in_features=192, out_features=576, bias=True),\n",
       " 'features.3.0.attn.proj': Linear(in_features=192, out_features=192, bias=True),\n",
       " 'features.3.0.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=6, bias=False)\n",
       " ),\n",
       " 'features.3.0.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.3.0.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.3.0.attn.cpb_mlp.2': Linear(in_features=512, out_features=6, bias=False),\n",
       " 'features.3.0.stochastic_depth': StochasticDepth(p=0.02608695652173913, mode=row),\n",
       " 'features.3.0.norm2': LayerNorm((192,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.3.0.mlp': MLP(\n",
       "   (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.3.0.mlp.0': Linear(in_features=192, out_features=768, bias=True),\n",
       " 'features.3.0.mlp.1': GELU(approximate='none'),\n",
       " 'features.3.0.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.3.0.mlp.3': Linear(in_features=768, out_features=192, bias=True),\n",
       " 'features.3.0.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.3.1': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "     (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.03913043478260869, mode=row)\n",
       "   (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.3.1.norm1': LayerNorm((192,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.3.1.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "   (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.3.1.attn.qkv': Linear(in_features=192, out_features=576, bias=True),\n",
       " 'features.3.1.attn.proj': Linear(in_features=192, out_features=192, bias=True),\n",
       " 'features.3.1.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=6, bias=False)\n",
       " ),\n",
       " 'features.3.1.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.3.1.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.3.1.attn.cpb_mlp.2': Linear(in_features=512, out_features=6, bias=False),\n",
       " 'features.3.1.stochastic_depth': StochasticDepth(p=0.03913043478260869, mode=row),\n",
       " 'features.3.1.norm2': LayerNorm((192,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.3.1.mlp': MLP(\n",
       "   (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.3.1.mlp.0': Linear(in_features=192, out_features=768, bias=True),\n",
       " 'features.3.1.mlp.1': GELU(approximate='none'),\n",
       " 'features.3.1.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.3.1.mlp.3': Linear(in_features=768, out_features=192, bias=True),\n",
       " 'features.3.1.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.4': PatchMergingV2(\n",
       "   (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "   (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " 'features.4.reduction': Linear(in_features=768, out_features=384, bias=False),\n",
       " 'features.4.norm': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5': Sequential(\n",
       "   (0): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.05217391304347826, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (1): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (2): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.07826086956521738, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (3): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.09130434782608696, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (4): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.10434782608695652, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (5): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.11739130434782608, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (6): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (7): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.14347826086956522, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (8): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.15652173913043477, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (9): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.16956521739130434, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (10): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (11): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (12): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.20869565217391303, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (13): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.2217391304347826, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (14): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.23478260869565215, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (15): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.24782608695652175, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (16): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (17): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "       (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.27391304347826084, mode=row)\n",
       "     (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'features.5.0': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.05217391304347826, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.0.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.0.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.0.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.0.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.0.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.0.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.0.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.0.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.0.stochastic_depth': StochasticDepth(p=0.05217391304347826, mode=row),\n",
       " 'features.5.0.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.0.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.0.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.0.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.0.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.0.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.0.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.1': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.1.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.1.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.1.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.1.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.1.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.1.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.1.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.1.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.1.stochastic_depth': StochasticDepth(p=0.06521739130434782, mode=row),\n",
       " 'features.5.1.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.1.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.1.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.1.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.1.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.1.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.1.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.2': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.07826086956521738, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.2.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.2.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.2.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.2.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.2.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.2.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.2.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.2.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.2.stochastic_depth': StochasticDepth(p=0.07826086956521738, mode=row),\n",
       " 'features.5.2.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.2.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.2.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.2.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.2.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.2.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.2.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.3': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.09130434782608696, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.3.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.3.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.3.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.3.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.3.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.3.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.3.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.3.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.3.stochastic_depth': StochasticDepth(p=0.09130434782608696, mode=row),\n",
       " 'features.5.3.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.3.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.3.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.3.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.3.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.3.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.3.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.4': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.10434782608695652, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.4.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.4.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.4.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.4.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.4.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.4.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.4.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.4.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.4.stochastic_depth': StochasticDepth(p=0.10434782608695652, mode=row),\n",
       " 'features.5.4.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.4.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.4.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.4.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.4.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.4.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.4.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.5': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.11739130434782608, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.5.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.5.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.5.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.5.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.5.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.5.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.5.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.5.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.5.stochastic_depth': StochasticDepth(p=0.11739130434782608, mode=row),\n",
       " 'features.5.5.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.5.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.5.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.5.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.5.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.5.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.5.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.6': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.6.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.6.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.6.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.6.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.6.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.6.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.6.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.6.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.6.stochastic_depth': StochasticDepth(p=0.13043478260869565, mode=row),\n",
       " 'features.5.6.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.6.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.6.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.6.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.6.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.6.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.6.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.7': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.14347826086956522, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.7.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.7.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.7.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.7.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.7.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.7.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.7.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.7.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.7.stochastic_depth': StochasticDepth(p=0.14347826086956522, mode=row),\n",
       " 'features.5.7.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.7.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.7.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.7.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.7.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.7.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.7.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.8': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.15652173913043477, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.8.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.8.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.8.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.8.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.8.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.8.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.8.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.8.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.8.stochastic_depth': StochasticDepth(p=0.15652173913043477, mode=row),\n",
       " 'features.5.8.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.8.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.8.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.8.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.8.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.8.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.8.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.9': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.16956521739130434, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.9.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.9.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.9.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.9.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.9.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.9.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.9.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.9.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.9.stochastic_depth': StochasticDepth(p=0.16956521739130434, mode=row),\n",
       " 'features.5.9.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.9.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.9.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.9.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.9.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.9.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.9.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.10': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.10.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.10.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.10.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.10.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.10.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.10.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.10.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.10.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.10.stochastic_depth': StochasticDepth(p=0.1826086956521739, mode=row),\n",
       " 'features.5.10.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.10.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.10.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.10.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.10.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.10.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.10.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.11': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.11.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.11.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.11.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.11.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.11.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.11.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.11.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.11.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.11.stochastic_depth': StochasticDepth(p=0.1956521739130435, mode=row),\n",
       " 'features.5.11.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.11.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.11.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.11.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.11.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.11.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.11.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.12': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.20869565217391303, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.12.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.12.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.12.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.12.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.12.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.12.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.12.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.12.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.12.stochastic_depth': StochasticDepth(p=0.20869565217391303, mode=row),\n",
       " 'features.5.12.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.12.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.12.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.12.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.12.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.12.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.12.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.13': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.2217391304347826, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.13.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.13.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.13.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.13.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.13.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.13.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.13.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.13.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.13.stochastic_depth': StochasticDepth(p=0.2217391304347826, mode=row),\n",
       " 'features.5.13.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.13.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.13.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.13.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.13.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.13.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.13.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.14': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.23478260869565215, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.14.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.14.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.14.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.14.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.14.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.14.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.14.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.14.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.14.stochastic_depth': StochasticDepth(p=0.23478260869565215, mode=row),\n",
       " 'features.5.14.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.14.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.14.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.14.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.14.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.14.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.14.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.15': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.24782608695652175, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.15.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.15.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.15.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.15.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.15.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.15.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.15.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.15.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.15.stochastic_depth': StochasticDepth(p=0.24782608695652175, mode=row),\n",
       " 'features.5.15.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.15.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.15.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.15.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.15.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.15.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.15.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.16': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.16.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.16.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.16.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.16.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.16.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.16.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.16.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.16.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.16.stochastic_depth': StochasticDepth(p=0.2608695652173913, mode=row),\n",
       " 'features.5.16.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.16.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.16.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.16.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.16.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.16.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.16.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.17': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "     (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.27391304347826084, mode=row)\n",
       "   (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.17.norm1': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.17.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "   (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.5.17.attn.qkv': Linear(in_features=384, out_features=1152, bias=True),\n",
       " 'features.5.17.attn.proj': Linear(in_features=384, out_features=384, bias=True),\n",
       " 'features.5.17.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=12, bias=False)\n",
       " ),\n",
       " 'features.5.17.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.5.17.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.5.17.attn.cpb_mlp.2': Linear(in_features=512, out_features=12, bias=False),\n",
       " 'features.5.17.stochastic_depth': StochasticDepth(p=0.27391304347826084, mode=row),\n",
       " 'features.5.17.norm2': LayerNorm((384,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.5.17.mlp': MLP(\n",
       "   (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.5.17.mlp.0': Linear(in_features=384, out_features=1536, bias=True),\n",
       " 'features.5.17.mlp.1': GELU(approximate='none'),\n",
       " 'features.5.17.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.5.17.mlp.3': Linear(in_features=1536, out_features=384, bias=True),\n",
       " 'features.5.17.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.6': PatchMergingV2(\n",
       "   (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "   (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       " ),\n",
       " 'features.6.reduction': Linear(in_features=1536, out_features=768, bias=False),\n",
       " 'features.6.norm': LayerNorm((768,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.7': Sequential(\n",
       "   (0): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "       (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.28695652173913044, mode=row)\n",
       "     (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       "   (1): SwinTransformerBlockV2(\n",
       "     (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     (attn): ShiftedWindowAttentionV2(\n",
       "       (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "       (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "       (cpb_mlp): Sequential(\n",
       "         (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "         (1): ReLU(inplace=True)\n",
       "         (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "       )\n",
       "     )\n",
       "     (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "     (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "     (mlp): MLP(\n",
       "       (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "       (1): GELU(approximate='none')\n",
       "       (2): Dropout(p=0.0, inplace=False)\n",
       "       (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "       (4): Dropout(p=0.0, inplace=False)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'features.7.0': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.28695652173913044, mode=row)\n",
       "   (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.7.0.norm1': LayerNorm((768,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.7.0.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.7.0.attn.qkv': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'features.7.0.attn.proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'features.7.0.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=24, bias=False)\n",
       " ),\n",
       " 'features.7.0.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.7.0.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.7.0.attn.cpb_mlp.2': Linear(in_features=512, out_features=24, bias=False),\n",
       " 'features.7.0.stochastic_depth': StochasticDepth(p=0.28695652173913044, mode=row),\n",
       " 'features.7.0.norm2': LayerNorm((768,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.7.0.mlp': MLP(\n",
       "   (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.7.0.mlp.0': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'features.7.0.mlp.1': GELU(approximate='none'),\n",
       " 'features.7.0.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.7.0.mlp.3': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'features.7.0.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'features.7.1': SwinTransformerBlockV2(\n",
       "   (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (attn): ShiftedWindowAttentionV2(\n",
       "     (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "     (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "     (cpb_mlp): Sequential(\n",
       "       (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "       (1): ReLU(inplace=True)\n",
       "       (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "     )\n",
       "   )\n",
       "   (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "   (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "   (mlp): MLP(\n",
       "     (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "     (1): GELU(approximate='none')\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "     (4): Dropout(p=0.0, inplace=False)\n",
       "   )\n",
       " ),\n",
       " 'features.7.1.norm1': LayerNorm((768,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.7.1.attn': ShiftedWindowAttentionV2(\n",
       "   (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "   (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "   (cpb_mlp): Sequential(\n",
       "     (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "     (1): ReLU(inplace=True)\n",
       "     (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "   )\n",
       " ),\n",
       " 'features.7.1.attn.qkv': Linear(in_features=768, out_features=2304, bias=True),\n",
       " 'features.7.1.attn.proj': Linear(in_features=768, out_features=768, bias=True),\n",
       " 'features.7.1.attn.cpb_mlp': Sequential(\n",
       "   (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "   (1): ReLU(inplace=True)\n",
       "   (2): Linear(in_features=512, out_features=24, bias=False)\n",
       " ),\n",
       " 'features.7.1.attn.cpb_mlp.0': Linear(in_features=2, out_features=512, bias=True),\n",
       " 'features.7.1.attn.cpb_mlp.1': ReLU(inplace=True),\n",
       " 'features.7.1.attn.cpb_mlp.2': Linear(in_features=512, out_features=24, bias=False),\n",
       " 'features.7.1.stochastic_depth': StochasticDepth(p=0.3, mode=row),\n",
       " 'features.7.1.norm2': LayerNorm((768,), eps=1e-05, elementwise_affine=True),\n",
       " 'features.7.1.mlp': MLP(\n",
       "   (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "   (1): GELU(approximate='none')\n",
       "   (2): Dropout(p=0.0, inplace=False)\n",
       "   (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "   (4): Dropout(p=0.0, inplace=False)\n",
       " ),\n",
       " 'features.7.1.mlp.0': Linear(in_features=768, out_features=3072, bias=True),\n",
       " 'features.7.1.mlp.1': GELU(approximate='none'),\n",
       " 'features.7.1.mlp.2': Dropout(p=0.0, inplace=False),\n",
       " 'features.7.1.mlp.3': Linear(in_features=3072, out_features=768, bias=True),\n",
       " 'features.7.1.mlp.4': Dropout(p=0.0, inplace=False),\n",
       " 'norm': LayerNorm((768,), eps=1e-05, elementwise_affine=True),\n",
       " 'permute': Permute(),\n",
       " 'avgpool': AdaptiveAvgPool2d(output_size=1),\n",
       " 'flatten': Flatten(start_dim=1, end_dim=-1),\n",
       " 'head': Linear(in_features=768, out_features=1000, bias=True)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:34:04.135483Z",
     "start_time": "2024-06-27T19:34:04.129296Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "63a2c937cac21185",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): Permute()\n",
       "      (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.013043478260869565, mode=row)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02608695652173913, mode=row)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03913043478260869, mode=row)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05217391304347826, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07826086956521738, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09130434782608696, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10434782608695652, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11739130434782608, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14347826086956522, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15652173913043477, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16956521739130434, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.20869565217391303, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2217391304347826, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.23478260869565215, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.24782608695652175, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.27391304347826084, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.28695652173913044, mode=row)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (permute): Permute()\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T18:10:40.276785Z",
     "start_time": "2024-06-27T18:10:40.198105Z"
    }
   },
   "cell_type": "code",
   "source": "summary(model, input_size=(1, 3, 256, 256),depth=7, col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"])",
   "id": "f434172fb13879f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "===========================================================================================================================================================\n",
       "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Trainable\n",
       "===========================================================================================================================================================\n",
       "SwinTransformer                                         [1, 3, 256, 256]          [1, 1000]                 --                        True\n",
       "Sequential: 1-1                                       [1, 3, 256, 256]          [1, 8, 8, 768]            --                        True\n",
       "    Sequential: 2-1                                  [1, 3, 256, 256]          [1, 64, 64, 96]           --                        True\n",
       "        Conv2d: 3-1                                 [1, 3, 256, 256]          [1, 96, 64, 64]           4,704                     True\n",
       "        Permute: 3-2                                [1, 96, 64, 64]           [1, 64, 64, 96]           --                        --\n",
       "        LayerNorm: 3-3                              [1, 64, 64, 96]           [1, 64, 64, 96]           192                       True\n",
       "    Sequential: 2-2                                  [1, 64, 64, 96]           [1, 64, 64, 96]           --                        True\n",
       "        SwinTransformerBlockV2: 3-4                 [1, 64, 64, 96]           [1, 64, 64, 96]           --                        True\n",
       "            ShiftedWindowAttentionV2: 4-1          [1, 64, 64, 96]           [1, 64, 64, 96]           37,251                    True\n",
       "                Sequential: 5-1                   [1, 15, 15, 2]            [1, 15, 15, 3]            --                        True\n",
       "                    Linear: 6-1                  [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-2                    [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-3                  [1, 15, 15, 512]          [1, 15, 15, 3]            1,536                     True\n",
       "            LayerNorm: 4-2                         [1, 64, 64, 96]           [1, 64, 64, 96]           192                       True\n",
       "            StochasticDepth: 4-3                   [1, 64, 64, 96]           [1, 64, 64, 96]           --                        --\n",
       "            MLP: 4-4                               [1, 64, 64, 96]           [1, 64, 64, 96]           --                        True\n",
       "                Linear: 5-2                       [1, 64, 64, 96]           [1, 64, 64, 384]          37,248                    True\n",
       "                GELU: 5-3                         [1, 64, 64, 384]          [1, 64, 64, 384]          --                        --\n",
       "                Dropout: 5-4                      [1, 64, 64, 384]          [1, 64, 64, 384]          --                        --\n",
       "                Linear: 5-5                       [1, 64, 64, 384]          [1, 64, 64, 96]           36,960                    True\n",
       "                Dropout: 5-6                      [1, 64, 64, 96]           [1, 64, 64, 96]           --                        --\n",
       "            LayerNorm: 4-5                         [1, 64, 64, 96]           [1, 64, 64, 96]           192                       True\n",
       "            StochasticDepth: 4-6                   [1, 64, 64, 96]           [1, 64, 64, 96]           --                        --\n",
       "        SwinTransformerBlockV2: 3-5                 [1, 64, 64, 96]           [1, 64, 64, 96]           --                        True\n",
       "            ShiftedWindowAttentionV2: 4-7          [1, 64, 64, 96]           [1, 64, 64, 96]           37,251                    True\n",
       "                Sequential: 5-7                   [1, 15, 15, 2]            [1, 15, 15, 3]            --                        True\n",
       "                    Linear: 6-4                  [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-5                    [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-6                  [1, 15, 15, 512]          [1, 15, 15, 3]            1,536                     True\n",
       "            LayerNorm: 4-8                         [1, 64, 64, 96]           [1, 64, 64, 96]           192                       True\n",
       "            StochasticDepth: 4-9                   [1, 64, 64, 96]           [1, 64, 64, 96]           --                        --\n",
       "            MLP: 4-10                              [1, 64, 64, 96]           [1, 64, 64, 96]           --                        True\n",
       "                Linear: 5-8                       [1, 64, 64, 96]           [1, 64, 64, 384]          37,248                    True\n",
       "                GELU: 5-9                         [1, 64, 64, 384]          [1, 64, 64, 384]          --                        --\n",
       "                Dropout: 5-10                     [1, 64, 64, 384]          [1, 64, 64, 384]          --                        --\n",
       "                Linear: 5-11                      [1, 64, 64, 384]          [1, 64, 64, 96]           36,960                    True\n",
       "                Dropout: 5-12                     [1, 64, 64, 96]           [1, 64, 64, 96]           --                        --\n",
       "            LayerNorm: 4-11                        [1, 64, 64, 96]           [1, 64, 64, 96]           192                       True\n",
       "            StochasticDepth: 4-12                  [1, 64, 64, 96]           [1, 64, 64, 96]           --                        --\n",
       "    PatchMergingV2: 2-3                              [1, 64, 64, 96]           [1, 32, 32, 192]          --                        True\n",
       "        Linear: 3-6                                 [1, 32, 32, 384]          [1, 32, 32, 192]          73,728                    True\n",
       "        LayerNorm: 3-7                              [1, 32, 32, 192]          [1, 32, 32, 192]          384                       True\n",
       "    Sequential: 2-4                                  [1, 32, 32, 192]          [1, 32, 32, 192]          --                        True\n",
       "        SwinTransformerBlockV2: 3-8                 [1, 32, 32, 192]          [1, 32, 32, 192]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-13         [1, 32, 32, 192]          [1, 32, 32, 192]          148,230                   True\n",
       "                Sequential: 5-13                  [1, 15, 15, 2]            [1, 15, 15, 6]            --                        True\n",
       "                    Linear: 6-7                  [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-8                    [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-9                  [1, 15, 15, 512]          [1, 15, 15, 6]            3,072                     True\n",
       "            LayerNorm: 4-14                        [1, 32, 32, 192]          [1, 32, 32, 192]          384                       True\n",
       "            StochasticDepth: 4-15                  [1, 32, 32, 192]          [1, 32, 32, 192]          --                        --\n",
       "            MLP: 4-16                              [1, 32, 32, 192]          [1, 32, 32, 192]          --                        True\n",
       "                Linear: 5-14                      [1, 32, 32, 192]          [1, 32, 32, 768]          148,224                   True\n",
       "                GELU: 5-15                        [1, 32, 32, 768]          [1, 32, 32, 768]          --                        --\n",
       "                Dropout: 5-16                     [1, 32, 32, 768]          [1, 32, 32, 768]          --                        --\n",
       "                Linear: 5-17                      [1, 32, 32, 768]          [1, 32, 32, 192]          147,648                   True\n",
       "                Dropout: 5-18                     [1, 32, 32, 192]          [1, 32, 32, 192]          --                        --\n",
       "            LayerNorm: 4-17                        [1, 32, 32, 192]          [1, 32, 32, 192]          384                       True\n",
       "            StochasticDepth: 4-18                  [1, 32, 32, 192]          [1, 32, 32, 192]          --                        --\n",
       "        SwinTransformerBlockV2: 3-9                 [1, 32, 32, 192]          [1, 32, 32, 192]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-19         [1, 32, 32, 192]          [1, 32, 32, 192]          148,230                   True\n",
       "                Sequential: 5-19                  [1, 15, 15, 2]            [1, 15, 15, 6]            --                        True\n",
       "                    Linear: 6-10                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-11                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-12                 [1, 15, 15, 512]          [1, 15, 15, 6]            3,072                     True\n",
       "            LayerNorm: 4-20                        [1, 32, 32, 192]          [1, 32, 32, 192]          384                       True\n",
       "            StochasticDepth: 4-21                  [1, 32, 32, 192]          [1, 32, 32, 192]          --                        --\n",
       "            MLP: 4-22                              [1, 32, 32, 192]          [1, 32, 32, 192]          --                        True\n",
       "                Linear: 5-20                      [1, 32, 32, 192]          [1, 32, 32, 768]          148,224                   True\n",
       "                GELU: 5-21                        [1, 32, 32, 768]          [1, 32, 32, 768]          --                        --\n",
       "                Dropout: 5-22                     [1, 32, 32, 768]          [1, 32, 32, 768]          --                        --\n",
       "                Linear: 5-23                      [1, 32, 32, 768]          [1, 32, 32, 192]          147,648                   True\n",
       "                Dropout: 5-24                     [1, 32, 32, 192]          [1, 32, 32, 192]          --                        --\n",
       "            LayerNorm: 4-23                        [1, 32, 32, 192]          [1, 32, 32, 192]          384                       True\n",
       "            StochasticDepth: 4-24                  [1, 32, 32, 192]          [1, 32, 32, 192]          --                        --\n",
       "    PatchMergingV2: 2-5                              [1, 32, 32, 192]          [1, 16, 16, 384]          --                        True\n",
       "        Linear: 3-10                                [1, 16, 16, 768]          [1, 16, 16, 384]          294,912                   True\n",
       "        LayerNorm: 3-11                             [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "    Sequential: 2-6                                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "        SwinTransformerBlockV2: 3-12                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-25         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-25                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-13                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-14                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-15                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-26                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-27                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-28                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-26                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-27                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-28                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-29                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-30                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-29                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-30                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-13                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-31         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-31                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-16                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-17                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-18                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-32                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-33                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-34                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-32                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-33                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-34                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-35                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-36                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-35                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-36                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-14                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-37         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-37                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-19                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-20                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-21                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-38                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-39                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-40                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-38                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-39                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-40                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-41                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-42                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-41                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-42                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-15                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-43         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-43                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-22                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-23                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-24                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-44                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-45                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-46                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-44                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-45                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-46                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-47                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-48                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-47                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-48                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-16                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-49         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-49                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-25                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-26                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-27                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-50                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-51                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-52                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-50                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-51                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-52                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-53                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-54                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-53                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-54                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-17                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-55         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-55                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-28                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-29                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-30                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-56                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-57                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-58                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-56                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-57                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-58                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-59                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-60                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-59                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-60                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-18                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-61         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-61                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-31                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-32                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-33                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-62                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-63                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-64                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-62                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-63                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-64                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-65                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-66                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-65                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-66                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-19                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-67         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-67                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-34                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-35                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-36                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-68                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-69                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-70                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-68                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-69                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-70                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-71                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-72                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-71                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-72                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-20                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-73         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-73                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-37                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-38                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-39                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-74                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-75                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-76                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-74                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-75                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-76                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-77                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-78                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-77                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-78                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-21                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-79         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-79                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-40                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-41                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-42                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-80                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-81                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-82                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-80                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-81                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-82                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-83                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-84                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-83                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-84                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-22                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-85         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-85                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-43                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-44                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-45                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-86                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-87                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-88                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-86                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-87                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-88                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-89                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-90                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-89                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-90                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-23                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-91         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-91                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-46                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-47                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-48                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-92                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-93                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-94                              [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-92                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-93                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-94                     [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-95                      [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-96                     [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-95                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-96                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-24                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-97         [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-97                  [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-49                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-50                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-51                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-98                        [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-99                  [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-100                             [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-98                      [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-99                        [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-100                    [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-101                     [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-102                    [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-101                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-102                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-25                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-103        [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-103                 [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-52                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-53                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-54                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-104                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-105                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-106                             [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-104                     [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-105                       [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-106                    [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-107                     [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-108                    [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-107                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-108                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-26                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-109        [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-109                 [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-55                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-56                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-57                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-110                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-111                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-112                             [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-110                     [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-111                       [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-112                    [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-113                     [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-114                    [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-113                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-114                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-27                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-115        [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-115                 [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-58                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-59                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-60                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-116                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-117                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-118                             [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-116                     [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-117                       [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-118                    [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-119                     [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-120                    [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-119                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-120                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-28                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-121        [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-121                 [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-61                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-62                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-63                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-122                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-123                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-124                             [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-122                     [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-123                       [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-124                    [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-125                     [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-126                    [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-125                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-126                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "        SwinTransformerBlockV2: 3-29                [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "            ShiftedWindowAttentionV2: 4-127        [1, 16, 16, 384]          [1, 16, 16, 384]          591,372                   True\n",
       "                Sequential: 5-127                 [1, 15, 15, 2]            [1, 15, 15, 12]           --                        True\n",
       "                    Linear: 6-64                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-65                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-66                 [1, 15, 15, 512]          [1, 15, 15, 12]           6,144                     True\n",
       "            LayerNorm: 4-128                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-129                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            MLP: 4-130                             [1, 16, 16, 384]          [1, 16, 16, 384]          --                        True\n",
       "                Linear: 5-128                     [1, 16, 16, 384]          [1, 16, 16, 1536]         591,360                   True\n",
       "                GELU: 5-129                       [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Dropout: 5-130                    [1, 16, 16, 1536]         [1, 16, 16, 1536]         --                        --\n",
       "                Linear: 5-131                     [1, 16, 16, 1536]         [1, 16, 16, 384]          590,208                   True\n",
       "                Dropout: 5-132                    [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "            LayerNorm: 4-131                       [1, 16, 16, 384]          [1, 16, 16, 384]          768                       True\n",
       "            StochasticDepth: 4-132                 [1, 16, 16, 384]          [1, 16, 16, 384]          --                        --\n",
       "    PatchMergingV2: 2-7                              [1, 16, 16, 384]          [1, 8, 8, 768]            --                        True\n",
       "        Linear: 3-30                                [1, 8, 8, 1536]           [1, 8, 8, 768]            1,179,648                 True\n",
       "        LayerNorm: 3-31                             [1, 8, 8, 768]            [1, 8, 8, 768]            1,536                     True\n",
       "    Sequential: 2-8                                  [1, 8, 8, 768]            [1, 8, 8, 768]            --                        True\n",
       "        SwinTransformerBlockV2: 3-32                [1, 8, 8, 768]            [1, 8, 8, 768]            --                        True\n",
       "            ShiftedWindowAttentionV2: 4-133        [1, 8, 8, 768]            [1, 8, 8, 768]            2,362,392                 True\n",
       "                Sequential: 5-133                 [1, 15, 15, 2]            [1, 15, 15, 24]           --                        True\n",
       "                    Linear: 6-67                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-68                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-69                 [1, 15, 15, 512]          [1, 15, 15, 24]           12,288                    True\n",
       "            LayerNorm: 4-134                       [1, 8, 8, 768]            [1, 8, 8, 768]            1,536                     True\n",
       "            StochasticDepth: 4-135                 [1, 8, 8, 768]            [1, 8, 8, 768]            --                        --\n",
       "            MLP: 4-136                             [1, 8, 8, 768]            [1, 8, 8, 768]            --                        True\n",
       "                Linear: 5-134                     [1, 8, 8, 768]            [1, 8, 8, 3072]           2,362,368                 True\n",
       "                GELU: 5-135                       [1, 8, 8, 3072]           [1, 8, 8, 3072]           --                        --\n",
       "                Dropout: 5-136                    [1, 8, 8, 3072]           [1, 8, 8, 3072]           --                        --\n",
       "                Linear: 5-137                     [1, 8, 8, 3072]           [1, 8, 8, 768]            2,360,064                 True\n",
       "                Dropout: 5-138                    [1, 8, 8, 768]            [1, 8, 8, 768]            --                        --\n",
       "            LayerNorm: 4-137                       [1, 8, 8, 768]            [1, 8, 8, 768]            1,536                     True\n",
       "            StochasticDepth: 4-138                 [1, 8, 8, 768]            [1, 8, 8, 768]            --                        --\n",
       "        SwinTransformerBlockV2: 3-33                [1, 8, 8, 768]            [1, 8, 8, 768]            --                        True\n",
       "            ShiftedWindowAttentionV2: 4-139        [1, 8, 8, 768]            [1, 8, 8, 768]            2,362,392                 True\n",
       "                Sequential: 5-139                 [1, 15, 15, 2]            [1, 15, 15, 24]           --                        True\n",
       "                    Linear: 6-70                 [1, 15, 15, 2]            [1, 15, 15, 512]          1,536                     True\n",
       "                    ReLU: 6-71                   [1, 15, 15, 512]          [1, 15, 15, 512]          --                        --\n",
       "                    Linear: 6-72                 [1, 15, 15, 512]          [1, 15, 15, 24]           12,288                    True\n",
       "            LayerNorm: 4-140                       [1, 8, 8, 768]            [1, 8, 8, 768]            1,536                     True\n",
       "            StochasticDepth: 4-141                 [1, 8, 8, 768]            [1, 8, 8, 768]            --                        --\n",
       "            MLP: 4-142                             [1, 8, 8, 768]            [1, 8, 8, 768]            --                        True\n",
       "                Linear: 5-140                     [1, 8, 8, 768]            [1, 8, 8, 3072]           2,362,368                 True\n",
       "                GELU: 5-141                       [1, 8, 8, 3072]           [1, 8, 8, 3072]           --                        --\n",
       "                Dropout: 5-142                    [1, 8, 8, 3072]           [1, 8, 8, 3072]           --                        --\n",
       "                Linear: 5-143                     [1, 8, 8, 3072]           [1, 8, 8, 768]            2,360,064                 True\n",
       "                Dropout: 5-144                    [1, 8, 8, 768]            [1, 8, 8, 768]            --                        --\n",
       "            LayerNorm: 4-143                       [1, 8, 8, 768]            [1, 8, 8, 768]            1,536                     True\n",
       "            StochasticDepth: 4-144                 [1, 8, 8, 768]            [1, 8, 8, 768]            --                        --\n",
       "LayerNorm: 1-2                                        [1, 8, 8, 768]            [1, 8, 8, 768]            1,536                     True\n",
       "Permute: 1-3                                          [1, 8, 8, 768]            [1, 768, 8, 8]            --                        --\n",
       "AdaptiveAvgPool2d: 1-4                                [1, 768, 8, 8]            [1, 768, 1, 1]            --                        --\n",
       "Flatten: 1-5                                          [1, 768, 1, 1]            [1, 768]                  --                        --\n",
       "Linear: 1-6                                           [1, 768]                  [1, 1000]                 769,000                   True\n",
       "===========================================================================================================================================================\n",
       "Total params: 49,737,442\n",
       "Trainable params: 49,737,442\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 53.26\n",
       "===========================================================================================================================================================\n",
       "Input size (MB): 0.79\n",
       "Forward/backward pass size (MB): 205.48\n",
       "Params size (MB): 135.99\n",
       "Estimated Total Size (MB): 342.25\n",
       "==========================================================================================================================================================="
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T17:48:20.344909Z",
     "start_time": "2024-06-27T17:48:20.339439Z"
    }
   },
   "cell_type": "code",
   "source": "model",
   "id": "a0b691383d9b34ef",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SwinTransformer(\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): Permute()\n",
       "      (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "          (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.013043478260869565, mode=row)\n",
       "        (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "      (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02608695652173913, mode=row)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "          (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.03913043478260869, mode=row)\n",
       "        (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "      (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05217391304347826, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07826086956521738, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.09130434782608696, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.10434782608695652, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11739130434782608, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14347826086956522, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15652173913043477, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.16956521739130434, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (12): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.20869565217391303, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (13): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2217391304347826, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (14): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.23478260869565215, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (15): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.24782608695652175, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (16): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (17): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "          (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.27391304347826084, mode=row)\n",
       "        (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): PatchMergingV2(\n",
       "      (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.28695652173913044, mode=row)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): SwinTransformerBlockV2(\n",
       "        (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): ShiftedWindowAttentionV2(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (cpb_mlp): Sequential(\n",
       "            (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "            (1): ReLU(inplace=True)\n",
       "            (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "        (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): MLP(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  (permute): Permute()\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "swin_v2_s",
   "id": "b6ffe3587b47961"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:38:54.518963Z",
     "start_time": "2024-06-27T19:38:53.513843Z"
    }
   },
   "cell_type": "code",
   "source": "face_swin = FaceSwin(train_from_default=True)",
   "id": "6cdd4cc2449dee6b",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:38:57.044350Z",
     "start_time": "2024-06-27T19:38:55.162992Z"
    }
   },
   "cell_type": "code",
   "source": "face_swin.to(\"cuda\")",
   "id": "cc5b58ee57e675a0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FaceSwin(\n",
       "  (features_extractor): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): Permute()\n",
       "        (2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=3, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.013043478260869565, mode=row)\n",
       "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=96, out_features=384, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=384, out_features=96, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
       "        (norm): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.02608695652173913, mode=row)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=6, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.03913043478260869, mode=row)\n",
       "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
       "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.05217391304347826, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.06521739130434782, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.07826086956521738, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.09130434782608696, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.10434782608695652, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.11739130434782608, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.13043478260869565, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.14347826086956522, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.15652173913043477, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.16956521739130434, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1826086956521739, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.1956521739130435, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (12): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.20869565217391303, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (13): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.2217391304347826, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (14): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.23478260869565215, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (15): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.24782608695652175, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (16): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.2608695652173913, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (17): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=12, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.27391304347826084, mode=row)\n",
       "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): PatchMergingV2(\n",
       "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
       "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (7): Sequential(\n",
       "        (0): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.28695652173913044, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): SwinTransformerBlockV2(\n",
       "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): ShiftedWindowAttentionV2(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (cpb_mlp): Sequential(\n",
       "              (0): Linear(in_features=2, out_features=512, bias=True)\n",
       "              (1): ReLU(inplace=True)\n",
       "              (2): Linear(in_features=512, out_features=24, bias=False)\n",
       "            )\n",
       "          )\n",
       "          (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): MLP(\n",
       "            (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (1): GELU(approximate='none')\n",
       "            (2): Dropout(p=0.0, inplace=False)\n",
       "            (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (4): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (2): Permute()\n",
       "    (3): AdaptiveAvgPool2d(output_size=1)\n",
       "    (4): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (head): Sequential(\n",
       "    (0): Linear(in_features=1536, out_features=512, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Dropout(p=0.2, inplace=True)\n",
       "    (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (4): GELU(approximate='none')\n",
       "    (5): Linear(in_features=128, out_features=1, bias=True)\n",
       "    (6): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T20:10:38.311786Z",
     "start_time": "2024-06-27T20:10:38.198201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "x1 = torch.randn(2, 3, 256, 256).to(\"cuda\")\n",
    "x2 = torch.randn(2, 3, 256, 256).to(\"cuda\")\n",
    "face_swin.forward(x1=x1, x2=x2)"
   ],
   "id": "603d13dbfe898c40",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4903],\n",
       "        [0.4875]], device='cuda:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T19:07:38.240325Z",
     "start_time": "2024-06-27T19:07:38.227044Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a5fd942dc4310580",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
